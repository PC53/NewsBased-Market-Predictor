{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f45273f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scrapy\n",
      "  Downloading Scrapy-2.6.2-py2.py3-none-any.whl (264 kB)\n",
      "     -------------------------------------- 264.5/264.5 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting pyOpenSSL>=16.2.0\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "     ---------------------------------------- 55.8/55.8 kB 2.8 MB/s eta 0:00:00\n",
      "Collecting cryptography>=2.0\n",
      "  Downloading cryptography-38.0.1-cp36-abi3-win_amd64.whl (2.4 MB)\n",
      "     ---------------------------------------- 2.4/2.4 MB 2.7 MB/s eta 0:00:00\n",
      "Collecting queuelib>=1.4.2\n",
      "  Downloading queuelib-1.6.2-py2.py3-none-any.whl (13 kB)\n",
      "Collecting parsel>=1.5.0\n",
      "  Downloading parsel-1.6.0-py2.py3-none-any.whl (13 kB)\n",
      "Collecting service-identity>=16.0.0\n",
      "  Downloading service_identity-21.1.0-py2.py3-none-any.whl (12 kB)\n",
      "Collecting Twisted>=17.9.0\n",
      "  Downloading Twisted-22.8.0-py3-none-any.whl (3.1 MB)\n",
      "     ---------------------------------------- 3.1/3.1 MB 3.7 MB/s eta 0:00:00\n",
      "Collecting itemloaders>=1.0.1\n",
      "  Downloading itemloaders-1.0.6-py3-none-any.whl (11 kB)\n",
      "Collecting w3lib>=1.17.0\n",
      "  Downloading w3lib-2.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting cssselect>=0.9.1\n",
      "  Downloading cssselect-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from scrapy) (4.9.1)\n",
      "Collecting zope.interface>=4.1.3\n",
      "  Downloading zope.interface-5.4.0-cp39-cp39-win_amd64.whl (210 kB)\n",
      "     -------------------------------------- 210.7/210.7 kB 6.5 MB/s eta 0:00:00\n",
      "Collecting protego>=0.1.15\n",
      "  Downloading Protego-0.2.1-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting tldextract\n",
      "  Downloading tldextract-3.3.1-py3-none-any.whl (93 kB)\n",
      "     ---------------------------------------- 93.6/93.6 kB 5.6 MB/s eta 0:00:00\n",
      "Collecting PyDispatcher>=2.0.5\n",
      "  Downloading PyDispatcher-2.0.6.tar.gz (38 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: setuptools in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from scrapy) (56.0.0)\n",
      "Collecting itemadapter>=0.1.0\n",
      "  Downloading itemadapter-0.7.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from cryptography>=2.0->scrapy) (1.15.1)\n",
      "Collecting jmespath>=0.9.5\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: six>=1.6.0 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from parsel>=1.5.0->scrapy) (1.16.0)\n",
      "Collecting pyasn1\n",
      "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Requirement already satisfied: attrs>=19.1.0 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from service-identity>=16.0.0->scrapy) (22.1.0)\n",
      "Collecting pyasn1-modules\n",
      "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Collecting twisted-iocpsupport<2,>=1.0.2\n",
      "  Downloading twisted_iocpsupport-1.0.2-cp39-cp39-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.6/45.6 kB ? eta 0:00:00\n",
      "Collecting Automat>=0.8.0\n",
      "  Downloading Automat-20.2.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting hyperlink>=17.1.1\n",
      "  Downloading hyperlink-21.0.0-py2.py3-none-any.whl (74 kB)\n",
      "     ---------------------------------------- 74.6/74.6 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting constantly>=15.1\n",
      "  Downloading constantly-15.1.0-py2.py3-none-any.whl (7.9 kB)\n",
      "Collecting typing-extensions>=3.6.5\n",
      "  Using cached typing_extensions-4.3.0-py3-none-any.whl (25 kB)\n",
      "Collecting incremental>=21.3.0\n",
      "  Downloading incremental-21.3.0-py2.py3-none-any.whl (15 kB)\n",
      "Collecting filelock>=3.0.8\n",
      "  Downloading filelock-3.8.0-py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: requests>=2.1.0 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from tldextract->scrapy) (2.28.1)\n",
      "Requirement already satisfied: idna in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from tldextract->scrapy) (3.3)\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Requirement already satisfied: pycparser in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from cffi>=1.12->cryptography>=2.0->scrapy) (2.21)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\chhal\\documents\\discord_bot\\newsbased-market-predictor\\newspredictorenv\\lib\\site-packages (from requests>=2.1.0->tldextract->scrapy) (2.1.1)\n",
      "Using legacy 'setup.py install' for PyDispatcher, since package 'wheel' is not installed.\n",
      "Installing collected packages: twisted-iocpsupport, PyDispatcher, pyasn1, incremental, constantly, zope.interface, w3lib, typing-extensions, queuelib, pyasn1-modules, protego, jmespath, itemadapter, hyperlink, filelock, cssselect, Automat, Twisted, requests-file, parsel, cryptography, tldextract, service-identity, pyOpenSSL, itemloaders, scrapy\n",
      "  Running setup.py install for PyDispatcher: started\n",
      "  Running setup.py install for PyDispatcher: finished with status 'done'\n",
      "Successfully installed Automat-20.2.0 PyDispatcher-2.0.6 Twisted-22.8.0 constantly-15.1.0 cryptography-38.0.1 cssselect-1.1.0 filelock-3.8.0 hyperlink-21.0.0 incremental-21.3.0 itemadapter-0.7.0 itemloaders-1.0.6 jmespath-1.0.1 parsel-1.6.0 protego-0.2.1 pyOpenSSL-22.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 queuelib-1.6.2 requests-file-1.5.1 scrapy-2.6.2 service-identity-21.1.0 tldextract-3.3.1 twisted-iocpsupport-1.0.2 typing-extensions-4.3.0 w3lib-2.0.1 zope.interface-5.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9be45d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scrapy as sp\n",
    "import os\n",
    "import time\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6273f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "START_DATE = date(2020,3,3) \n",
    "END_DATE = date(2022,8,30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1364f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class moneycontrol_spider(sp.Spider):\n",
    "    name = 'moneycontrol spider'\n",
    "    \n",
    "    def get_start_urls(self):\n",
    "        urls = []\n",
    "        base = 'https://www.google.com'\n",
    "        srt, end = START_DATE, START_DATE + timedelta(7)\n",
    "        while end<END_DATE:\n",
    "            query = f'/search?q=site:moneycontrol.com+after:{str(srt)}+before:{str(end)}&tbm=nws'\n",
    "\n",
    "            url = base+query\n",
    "            urls.append(url)\n",
    "\n",
    "            srt += timedelta(7)\n",
    "            end += timedelta(7)\n",
    "        return urls\n",
    "    \n",
    "    start_urls = get_start_urls()\n",
    "    \n",
    "    def parse(self,response):\n",
    "        \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newsPredictorEnv",
   "language": "python",
   "name": "newspredictorenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
